# sh：bash脚本

Bash 脚本，用于自动执行数据集数据下载过程。

1. 首先在当前位置创建一个名为 RawData 的目录并导航到该目录。
2. 将下载的每个数据集创建子目录。例如，它为 PhysioNet-2012 数据集创建 Physio2012_mega ，为空气质量数据集创建 AirQuality ，为电力数据集创建 Electricity ，以及 ETT 
3. 在每个子目录中，它使用 wget 命令从互联网下载必要的文件。它还使用 tar 或 unzip 命令解压下载的所有压缩文件。例如，它下载 PhysioNet-2012 数据集的多个 tar.gz 文件，使用 tar -zxf 提取它们，然后将提取的文件移动到名为 mega 的新目录中。
4. 该脚本还下载空气质量、电力和电力变压器温度数据集的数据。

运行时将使用四个数据集填充**RawData 目录：PhysioNet-2012、空气质量、电力和电力变压器温度 (ETT)**。数据集文件是从各种来源下载的，例如 PhysioNet 和 UCI 机器学习存储库。

要运行此脚本，您需要足够的权限和存储空间，并且运行该脚本的计算机需要具有网络连接才能访问脚本中提到的 URL。

## 用法

要运行此脚本，请在命令行中导航到此目录并运行以下命令：

```bash
sh data_downloading.sh
```

## 数据细节

公开数据集原始文件。

1. PhysioNet 2012数据集: 下载并解压训练、验证和测试三个tarball文件,以及对应的标签文件。
2. 空气质量数据集: 从UCI网站下载北京PM2.5数据集的zip文件。
3. 电力消费数据集: 从UCI网站下载LD2011_2014电力消费数据的zip文件。
4. ETT数据集: 从GitHub下载ETTm1子数据集的CSV文件。

下载后的数据被组织到RawData目录下的不同子目录中。

该脚本自动化了公开数据集的下载工作,为后续的数据预处理和模型训练提供了原始数据源。评论中给出了完整的bibtex引用信息,提醒用户在使用该代码时要正确引用。 