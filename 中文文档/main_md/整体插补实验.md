# 整体实验流程

run_models.py

## 源代码

## 代码结构解析

驱动程序脚本，用于在估算数据上运行各种模型。

脚本看起来支持运行各种模型，包括 Transformer Encoder、Self-Attention (SAITS)、BRITS（时间序列双向循环插补）和 MRNN（改进的循环神经网络）。

主要特点：

1. MODEL_DICT ：将模型名称映射到相应类对象的字典。您可以将新模型添加到此字典中，以使其可用于训练。
2. OPTIMIZER ：将优化器名称映射到相应的 PyTorch 类的字典。这使得在训练期间可以轻松使用不同的优化器。

本以一系列导入语句和初始化开始，例如设置随机种子以确保可重复性和抑制警告。

还使用了 Microsoft 的神经网络智能工具包 nni ，这是一个轻量级但功能强大的工具包，可帮助进行超参数调整、神经架构搜索、模型压缩等。但是， nni 导入位于 try 块中，因此如果未安装 nni ，脚本仍将运行。

主要是用于运行不同的时间序列预测模型。
主要内容:

1. 导入需要的Python库,包括argparse、math、os、warnings等常用库,以及PyTorch、TensorBoard等深度学习相关库。
2. 定义了一些常量,包括模型字典MODEL_DICT,优化器字典OPTIMIZER,随机种子RANDOM_SEED等。
3. 尝试导入nni库,用于神经网络 Intelligence(NNI)支持。
4. 从各模型文件导入具体的模型类,包括基于自注意力的Transformer和SAITS,基于RNN的BRITS和MRNN。
5. 从工具文件导入各种模型运行需要的组件,包括控制器、日志、保存/加载模型等函数。
6. 设置随机种子。
7. 这段代码定义了各种组件,并导入了需要的模型和工具,可以用来灵活地运行不同的时间序列预测模型,通过argparse等可以传入不同的参数控制模型的运行。



负责处理命令行参数、将数据写入 TensorBoard、处理训练步骤的结果以及执行每个训练步骤所需的任务。以下是每个功能的简要概述：

1. read_arguments(arg_parser, cfg_parser) ：此函数采用 argparse 对象和配置解析器对象作为输入。它使用从配置解析器对象读取的值更新 argparse 对象。然后返回更新后的 argparse 对象。当您有很多需要指定的参数时，这是一种非常有用的方法，并且它使代码更干净且更易于维护。
2. summary_write_into_tb(summary_writer, info_dict, step, stage) ：此函数将各种指标写入 TensorBoard 日志文件。这些指标包括总损失、插补损失、插补平均绝对误差 (MAE)、重建损失和重建 MAE。该函数使用 torch.utils.tensorboard 包中 SummaryWriter 对象的 add_scalar 方法来完成此操作。
3. result_processing(results) ：此函数根据训练步骤的结果计算总损失。看起来总损失被计算为插补损失和重建损失的加权和，具体取决于相应的标志 MIT 和 ORT 是否设置为 True。然后该函数返回更新后的结果字典。
4. process_each_training_step(results, optimizer, val_dataloader, training_controller, summary_writer, logger) ：此函数执行每个训练步骤所需的任务。

这些任务包括从训练控制器获取训练状态、根据需要应用梯度裁剪、反向传播总损失、使用优化器更新模型参数、将当前结果写入 TensorBoard、每 n 步验证模型（其中 n 由下式指定） eval_every_n_steps 参数），并确定是否提前停止训练。如果触发提前停止，函数返回True；否则，返回 False。此方法中调用的 validate 函数未在提供的代码中定义，因此您需要单独定义它或提供定义以便完整理解。

函数来处理模型训练过程中的一些步骤:

1. read_arguments: 从配置文件读取各种参数,如文件路径、数据集信息、训练设置、模型设置等。
2. summary_write_into_tb: 将一步的训练信息写入TensorBoard汇总文件。
3. result_processing: 对每个step的结果(loss等)进行加权和计算,得到最终的loss。
4. process_each_training_step: 处理每个训练step的过程,包括:

   - 调用训练控制器获取状态
   - 梯度裁剪
   - 损失回传优化
   - 写入TensorBoard - 编写 TensorBoard
   - 每隔eval_every_n_steps进行一次验证
   - 如果验证时提前停止,则返回True

这些函数将训练过程中的主要步骤模块化和封装,使训练代码更清晰简洁。 

model_processing和train两个函数,用于处理模型的训练和验证过程。
model_processing函数包含了对单个batch数据的前向传播和loss计算。它区分了train和val两个阶段,train阶段会调用process_each_training_step函数进行反向传播、优化等操作。
train函数则包含了整个模型的训练流程,包括:

- 遍历epoch
- 遍历dataloader获取batch数据
- 调用model_processing处理每个batch
- 如果验证时提前停止,则停止训练
这样通过这两个函数,可以清晰地组织模型的训练、验证、优化过程,使主训练逻辑更简洁。
model_processing负责单个batch的计算,train函数负责batch迭代和epoch迭代。

model_processing 和 train 这两个函数本质上是管理模型的训练过程。

1. model_processing ：此函数在训练或验证/测试阶段运行模型。它将数据、模型、阶段（“训练”或“测试”）以及仅训练阶段所需的其他可选参数作为参数。
在训练阶段，该函数首先将所有模型参数的梯度设置为零。然后，它将输入数据映射到正确的设备（例如 GPU）。根据模型类型，函数以不同的方式构建输入。
例如，BRITS 和 MRNN 模型需要单独输入前向和后向传递数据，而 Transformer 和 SAITS 模型则不需要。
一旦准备好输入，该函数就会处理模型的结果，计算总损失，并执行一个训练步骤（使用 process_each_training_step 函数）。如果模型配置为使用提前停止并且满足提前停止条件，则该函数将返回 True。如果使用缺失指标技术 (MIT)，此过程会略有不同。
在验证/测试阶段，该函数以与训练阶段类似的方式准备输入，然后简单地在这些输入上运行模型并处理结果。它返回输入和结果。

2. train ：该函数执行主训练循环。它以模型、优化器、训练和测试数据加载器、TensorBoard 的摘要编写器、训练控制器和记录器作为参数。
该函数首先设置训练的纪元数。然后进入嵌套循环结构：外循环遍历每个epoch，内循环遍历训练集中的每一批数据。对于每批数据，它都会运行 model_processing 函数，传递批次数据和模型以及其他参数。如果 model_processing 函数返回 True（表示应该提前停止），该函数将跳出批次循环并移至下一个纪元。如果在一个时期内触发提前停止，该函数将在该时期内跳出循环。
处理完所有 epoch 后，该函数会记录一条消息，指示训练已完成。

validate和test_trained_model两个函数,用于在验证集和测试集上评估模型。
validate函数在验证集上进行验证,包括:

- 对每个batch调用model_processing进行前向计算
- 收集预测结果和ground truth
- 计算验证集上的指标(loss、MAE等)
- 调用training_controller更新训练状态
- 写入TensorBoard - 编写 TensorBoard
- 如果需要保存模型,则保存
- 返回更新后的训练状态字典
test_trained_model函数在完整的测试集上评估模型,包括:

- 对每个batch调用model_processing进行前向计算
- 收集预测结果和ground truth
- 计算测试集上的指标(MAE、RMSE、MRE等)
- 保存测试指标到文件
这两个函数分别对验证集和测试集进行评测,validate关注的是模型训练过程中指标的实时监控,test_trained_model用来对最终模型进行全面评估。

validate 和 test_trained_model 函数分别处理模型的验证和测试阶段。

1. validate ：此函数对模型执行验证。它将模型、验证数据的数据加载器、TensorBoard 的摘要编写器、训练控制器和记录器作为参数。
该函数将模型设置为评估模式，这会禁用仅在训练期间使用的某些功能，例如 dropout。然后，它循环验证集中的每批数据，使用 model_processing 函数处理数据并收集结果。该函数收集有关模型性能的多项信息，包括总损失、重建损失、插补损失以及重建和插补的平均绝对误差 (MAE)。
处理所有数据后，该函数计算所有数据中每个指标的平均值并报告这些平均值。
该函数还根据 args.model_saving_strategy 中指定的条件检查是否应该保存模型。如果应该保存模型，该函数将使用 save_model 函数保存模型并记录保存模型的路径。
2. test_trained_model ：此函数评估模型在测试集上的性能。它将模型和测试数据的数据加载器作为参数。
与 validate 函数一样， test_trained_model 将模型设置为评估模式并循环测试集中的每批数据。对于每个批次，它使用 model_processing 函数处理数据并收集结果。处理所有数据后，该函数计算整个测试集上插补数据的 MAE、均方根误差 (RMSE) 和平均相对误差 (MRE)。
该函数报告这些指标以及模型中可训练参数的总数。它记录这些结果并将其写入 args.result_saving_path 指定的目录中名为“overall_performance_metrics.out”的文件中。

impute_all_missing_data 使用模型对所有训练集、验证集和测试集执行数据插补。

1. 使用 model.eval() 将模型设置为评估模式。
2. 然后它迭代数据加载器中提供的每个数据集（训练、验证、测试）。
3. 在每次迭代中，它都会收集数据索引和估算数据。数据通过模型转发以获得估算数据。
4. 迭代每个数据集后，将收集的索引和插补基于索引进行连接和排序，以确保样本的正确顺序。
5. 排序后的插补数据存储在 imputed_data_dict 字典中。
6. 最后，将字典中的估算数据写入 .h5 文件并保存在 args.result_saving_path 定义的路径中。 .h5 文件中的数据集分别命名为估算训练数据集、验证数据集和测试数据集的“估算训练集”、“估算数据集”和“估算测试集”。

当您想要生成并存储模型的输出以供进一步分析时，此函数非常有用。 .h5 文件格式通常用于存储大型数据集，并且可以被许多数据分析工具读取。

impute_all_missing_data函数,用于在训练/验证/测试集上的所有数据上进行缺失值填补。
主要逻辑包括:

1. 循环遍历训练、验证、测试数据集的DataLoader
2. 对每个batch,调用model的impute方法进行前向计算,得到填补结果
3. 收集batch级别的样本index和填补结果
4. 将batch级别的数据连接起来
5. 根据index排序,保证样本顺序一致
6. 将每个数据集的填补结果存入字典
7. 将字典中的三个数据集的填补结果写入HDF5文件
这样,通过该函数可以批量对全部数据进行填补,并保存在HDF5中,方便后续读取和分析。
主要通过model的impute方法实现了对缺失数据的自动填补。并且考虑了不同模型的输入格式兼容性。

该脚本允许配置、训练和测试机器学习模型以估算缺失数据。

1. 它首先解析命令行参数。其中包括配置文件的路径，无论是在测试模式下运行还是使用神经网络智能 (NNI) 的参数搜索模式运行。
2. 然后它检查配置文件是否存在并从此文件中读取参数。
3. 根据模型类型（变压器或循环神经网络），它会相应地配置模型参数。如果启用参数搜索模式，则从 NNI tuner获取下一个参数集。
4. 它断言必要的检查，以确保为模型保存策略、优化器类型和计算设备选择的选项有效。
5. 它使用指定的参数初始化数据加载器和模型。它还计算模型中可训练参数的数量并记录下来。
6. 如果在测试模式下运行，它将从指定路径加载预先训练的模型，准备测试数据加载器，测试模型，并在设置了相应标志的情况下估算丢失的数据。
7. 如果不在测试模式下，它会准备训练和验证数据加载器，初始化控制器以提前停止，计算每个时期的步数，然后启动训练过程。TensorBoard 日志保存到指定目录，以便训练过程可视化。
8. 该脚本最后记录所有操作均已完成。

该脚本是如何在 PyTorch 中构建机器学习实验的一个很好的示例，包括处理命令行参数、配置文件、日志记录、数据加载、模型初始化、训练和测试。

这段代码是模型的主要运行逻辑:

1.解析命令行参数和配置文件参数。
2.根据模型类型设置相应的模型参数。
3.构建数据加载器。
4.实例化模型。
5.如果是测试模式,则加载预训练模型进行测试;如果是训练模式,则构建优化器、训练控制器等,进入训练流程。
6.训练流程主要包括数据读取、模型前向计算、计算损失、反向传播、参数更新等步骤。同时会进行模型保存、日志记录、TensorBoard可视化等。
7.训练完成后,可以选择对所有数据进行缺失值填补。
所以这段代码完成了模型从参数解析、模型定义、数据加载、训练评估、到结果可视化的完整pipeline。
主要的高级功能包括:

- 支持命令行参数与配置文件参数
- 支持不同模型的统一定义和调用
- 支持测试已训练模型
- 支持模型训练与评估
- 支持日志、TensorBoard
- 支持Early Stopping - 支持提前停止
- 支持NNI自动超参调优
整体是一个通用的时间序列预测模型的训练框架。
